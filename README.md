# Coding 2_Labwork
## Lab 1
  Pac-Man
  In Lab 1, I created a demo of Pac-Man, which primarily includes 
  the definitions of Pac-Man, ghosts, and pellets, along with their 
  interaction logic.
## Lab 2
  In Lab 2, I created a moonlit snow scene using vectors for snowflake 
  motion, and developed a snowflake object. Leveraging inheritance and 
  polymorphism, I generated various snowflake types. Two sliders were 
  created to adjust the snowflakes' quantity and speed, allowing 
  interactive scene customization. 
## Lab 3
  In Lab 3, I developed a predator-prey interaction model using a canvas 
  with no boundaries to dynamically simulate the complex relationship of 
  predation and evasion found in nature. The model features 450 prey that 
  adhere to group behavior rules—including alignment, cohesion, separation, 
  and evasion from predators—allowing them to update their positions and 
  velocities accordingly. Predators, whose numbers can be adjusted via a slider, 
  pursue the prey. This setup vividly demonstrates the intricate dynamics of 
  natural predator-prey interactions.
## Lab4 Midterm assignment
This is our group's midterm assignment, "INFLUENCE INVASION" (you need to click with the kitten's left ear). 
## Lab 5
  In my Lab 5, I created a p5.js application that combines music visualization 
  with reading data from an Arduino serial port. This project uses data collected from 
  an Arduino ultrasonic distance sensor to drive the visualization effects. Based on the 
  range of values returned by the distance sensor, the application implements three different 
  types of music visualization effects on the canvas: a spectrum jumping effect when the data 
  value is between 0 and 10; a dynamic particle effect for values between 10 and 20; and an 
  audio waveform animation for values between 20 and 30.
## Lab 6
  In Lab 6, I created a dynamic text visualization by converting a letter into a series of points 
  using the font.textToPoints() method, for subsequent drawing. The dot matrix of the letter "A" 
  changes color and size based on the speed and position of mouse movement, thus generating a visual 
  display with wave and noise effects.
## Lab 7
  In lab7, I utilized p5.js and ml5.js's faceApi to create a real-time facial detection application 
  that captures and analyzes users' facial features through a webcam. It calculates the distance between 
  the upper and lower lips of the first detected face to determine if the mouth is open. Depending on 
  the degree of mouth opening, the application changes the background color accordingly: if the mouth 
  is detected to be open (distance greater than 9 pixels), the background turns red; otherwise, it 
  turns green. This type of application can be used in various scenarios, such as games, interactive 
  art projects, or any setting that requires facial interaction. This is also what I used for my final 
  project. 
